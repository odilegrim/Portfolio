---
title: "Bring Me The Horizon's changing repertoire"
author: "Odile Grim"
date: "March 2021" 
output: 
  flexdashboard::flex_dashboard:
    theme: journal
---
<style>                     
.navbar {
  color:#390a61;
  background-color:#7540a1;
  border-color:black;
}
.navbar-brand {
color:white!important;
}
.navbar-inverse .navbar-nav > li > a:hover,
.navbar-inverse .navbar-nav > li > a:focus {
    background-color: #72b7cc;
    color: white;
}
.navbar-inverse .navbar-nav > .active > a,
.navbar-inverse .navbar-nav > .active > a:hover,
.navbar-inverse .navbar-nav > .active > a:focus {
  color: white;
  background-color: #72b7cc;
}
.navbar-inverse .navbar-toggle:hover,
.navbar-inverse .navbar-toggle:focus {
  background-color: #72b7cc;
}
.navbar-inverse .navbar-collapse,
.navbar-inverse .navbar-form {
  border-color: #72b7cc;
}
.navbar-inverse .navbar-brand:hover,
.navbar-inverse .navbar-brand:focus {
  color: white;
  background-color: #72b7cc;
}
.storyboard-nav .sbframelist ul li.active {
  background-color:#7540a1;
  hover-color:#7540a1;
}
.storyboard-nav .sbframelist ul li.hover {
  background-color:#7540a1;
  hover-color:#7540a1;
}
.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus,
.dropdown-menu > li > a:active{
    color: black;
    text-decoration: none;
    background-color: #72b7cc!important; 
}
.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus,
.dropdown-menu > .active > a:active {
  color:white;
  background-color:#72b7cc!important;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #72b7cc;
}

</style>                    

```{r}
library(plotly)
library(spotifyr)
library(ggplot2)
library(tidyverse)
library(compmus)
library(gridExtra)
library(kknn)
library(tidymodels)
library(ggdendro)
library(heatmaply)
library(protoclust)
library(cluster)

get_conf_mat <- function(fit) {
  outcome <- .get_tune_outcome_names(fit)
  fit %>% 
    collect_predictions() %>% 
    conf_mat(truth = outcome, estimate = .pred_class)
}  

get_pr <- function(fit) {
  fit %>% 
    conf_mat_resampled() %>% 
    group_by(Prediction) %>% mutate(precision = Freq / sum(Freq)) %>% 
    group_by(Truth) %>% mutate(recall = Freq / sum(Freq)) %>% 
    ungroup() %>% filter(Prediction == Truth) %>% 
    select(class = Prediction, precision, recall)
}  

cache = TRUE


```




**Introduction** {data-icon="fa-map-marker-alt"}
===============================================================

### **What my analysis is about**
For this portfolio I will take the [repertoire of Bring Me The Horizon](https://open.spotify.com/artist/1Ffb6ejR6Fe5IamqA5oRUF) as my corpus. Since the release of their first four albums, which can, according to Google, all be classified as "metalcore", their music has progressed more towards alternative-/pop-/electronic-rock and they even released an [EP with experimental and electronic music](https://open.spotify.com/album/6yC6aLzX5knhWpKDidwxft). Having been in their fanbase since around 2013, when [*Sempiternal*](https://open.spotify.com/album/1tbhr4UJMpYgBjWhbhO3hW) was released, I myself experienced the changes in their music. As always, there are fans who argue that only the "old" music is good and the "new" music just isn't. My question is, what exactly has changed about their music, and are there any aspects which have remained similar to their early music? It could also be interesting to see whether there are any patterns in the popularity with regard to their "old" and "new" music. 

I have split Bring Me The Horizon's music into three different categories, **"Old music"**, their first four albums, **"New music"**, their three most recent releases, with exception of their experimental music from *Music to listen to~*, which is the third **"Experimental music"** category. This album isn't exactly representative of either their "new" or "old" music style, so I made it a separate category (hence "Experimental").

I definitely think that BMTH's music after 2013 has changed significantly compared to their earlier music and it will be most interesting to compare music from before and after that time. Specific interesting tracks I will look at would be their singles *Pray for Plagues*, *Chelsea Smile* and *Shadow Moses* from their earlier work and *Drown*, *Mantra* and *Ludens* from their more recent work, as singles are usually representative for the overall style of the album they belong to. Another factor I will use to pick some specific songs is popularity. As you will be able to see in the *analysis* part of the portfolio, BMTH's old music scores significantly lower on popularity, so it would be interesting to dig a little deeper into those songs and see if there could be a reason for this. Overall, I will focus more on the "old" and "new" music, but I will include the "experimental" music in some more general parts of the analysis.


### .........................................................................................................................................................................................................................................................................................................................................
![](https://www.impericon-mag.com/nl/wp-content/uploads/sites/7/2020/10/bringmethehorizon.jpg)


**General** {.storyboard data-icon="fa-music" data-navmenu="Analysis"}
=========================================================

### **First things first**: Different music styles over the years compared {data-commentary-width=450}

```{r, fig.width = 8.4}
library(tidyverse)
library(spotifyr)
library(plotly)

old <- get_playlist_audio_features("", "6oeRMX8XZ8IS7MCDb6Z1BG")
new <- get_playlist_audio_features("", "4k98rVhcCw54dhLaUMiyLK")
experimental <- get_playlist_audio_features("", "1EIpRI9TozVUiehlxAmmHq")

oldvsnew <-
  bind_rows(
    old %>% mutate(category = "Old music"),
    new %>% mutate(category = "New music"),
    experimental %>% mutate(category = "Experimental")
  )

oldvsnew_order <- oldvsnew                             
oldvsnew_order$category <- factor(oldvsnew_order$category,     
                         levels = c("Old music", 
                                    "New music", 
                                    "Experimental"))


differentstyles <- ggplot(oldvsnew_order, 
                          aes(x = valence, y = energy, color = speechiness, size = danceability)) +
  geom_jitter(alpha = 0.5) +
  facet_wrap(~category) +
  scale_color_gradient(low = "black", high = "purple")+
  theme_linedraw() +
  labs(title = "Bring Me The Horizon: different music styles") +
  theme(plot.title = element_text( 
    face = "bold", 
    color = "black",
    hjust = 0.5,
    size = 13)) +
  theme(legend.title = element_text(
    color = "black",
    size = 12
  )) +
  theme(axis.title = element_text(
    size = 12)) +
  xlab("Valence") + ylab("Energy") +
  theme(strip.text.x =  element_text(family = "mono")) +
  geom_text(
    aes(x = valence, y = energy, label = label),
    data = tibble(label = c("A Devastating 
    Liberation", 
                            "i apologise if 
    you feel something",
                            "Memorial"), 
                  category = c("Experimental", "New music", "Old music"), 
                  valence = c(0.15, 0.165, 0.12),
                  energy = c(0.17, 0.345, 0.0451)),
    color = "darkred",
    size = 3,
    family = "mono"
  )  +
  theme(text = element_text(family = "mono"))

ggplotly(differentstyles)
  
```

***

It is easily visible that BMTH's new music is much **more varied** than their old music. Considering that high energy + low valence = angry music, and high energy + high valence = happy music, we could conclude that their music has overall become **happier**. The experimental music has very low valence values, like BMTH's old music, and is also more angry and negative. Each category seems to have outliers that fall into the 'sad music' area, they are labeled in the plot.
  
With the highest **danceability (indicated by size)** score being 0.6 out of a possible maximum of 1, most of their music isn't very danceable, but their newer music generally scores higher. The **speechiness** seems to be higher with higher valence scores, but overall the music doesn't seem very speechy. Looking at all their work together, the music seems very energetic and seems to have progressed from negative and angry towards a more diverse and positive style (although the valence still lies mostly below 0.5), with almost a kind of "dip" back towards negativity in their experimental album. 

### **Popularity** scores for all of BMTH's albums {data-commentary-width=450}

```{r}

oldvsnew_releasedate <- oldvsnew %>%
  arrange(track.album.release_date)

ggplot(oldvsnew_releasedate, aes(track.album.name, track.popularity, 
                                                       color = category)) +
  geom_point(alpha = 0.6, size = 3) +
  scale_color_brewer(palette = "Dark2") +
  theme_linedraw() +
  scale_x_discrete(breaks = c("Count Your Blessings",
                              "Suicide Season",
                              "There is a Hell Believe Me I've Seen It. There is a Heaven Let's Keep it a Secret",
                              "Sempiternal (Expanded Edition)",
                              "That's The Spirit",
                              "amo",
                              "Music to listen to~dance to~blaze to~pray to~feed to~sleep to~talk to~grind to~trip to~breathe to~help to~hurt to~scroll to~roll to~love to~hate to~learn Too~plot to~play to~be to~feel to~breed to~sweat to~dream to~hide to~live to~die to~GO TO",
                              "POST HUMAN: SURVIVAL HORROR"),
                   labels = c("Count Your Blessings",
                              "Suicide Season", 
                              "There is a Hell...",
                              "Sempiternal",
                              "That's The Spirit",
                              "amo",
                              "Music to listen to~",
                              "POST HUMAN"),
                   limits = c("Count Your Blessings",
                              "Suicide Season",
                              "There is a Hell Believe Me I've Seen It. There is a Heaven Let's Keep it a Secret",
                              "Sempiternal (Expanded Edition)",
                              "That's The Spirit",
                              "amo",
                              "Music to listen to~dance to~blaze to~pray to~feed to~sleep to~talk to~grind to~trip to~breathe to~help to~hurt to~scroll to~roll to~love to~hate to~learn Too~plot to~play to~be to~feel to~breed to~sweat to~dream to~hide to~live to~die to~GO TO",
                              "POST HUMAN: SURVIVAL HORROR")
                     ) +
  theme(text = element_text(family = "mono")) +
  labs(y = "Popularity") +
  labs(title = "Track popularity per album") +
  theme(axis.title.x = element_blank()) +
  labs(color = "Category" ) +
  stat_summary(
    geom = "point",
    fun = "median",
    col = "darkred",
    size = 7,
    shape = 21,
    fill = "pink",
    alpha = 0.4
  ) +
  stat_summary(aes(group = 1), 
               fun = median, 
               geom = "line", 
               colour = "darkred",
               alpha = 0.3) +
  theme(axis.text.x = element_text(angle = 60, hjust = 1, size = 8)) 
```

***

This plot shows the popularity scores for the songs on all of Bring Me The Horizon's albums, they are in order of their release date from oldest to most recent. The bigger transparent red/pink circles show the **median for popularity** for each album. It is easy to see that their older music is the least popular of all and *That's The Spirit* and *POST HUMAN: SURVIVAL HORROR* are their most popular albums. Considering the fact that their music style really started changing on *Sempiternal*, it is not weird to see that the popularity shoots upwards from that album on. Of course, the experimental album *Music to listen to~* creates a big dip in popularity, since it is completely different from what the band usually produces and is not widely liked by fans.
  
**Chroma** {.storyboard data-icon="fa-music" data-navmenu="Analysis"}
=========================================================

### **Chromagrams** for popular and not so popular songs {data-commentary-width=450}

```{r}
cyfmh_chroma <- get_tidy_audio_analysis("0WSa1sucoNRcEeULlZVQXj") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

cyfmh_chromagram <- cyfmh_chroma %>%
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c(guide = "none", option = "magma") +
  theme(text = element_text(family = "mono")) +
  labs(title = "Can You Feel My Heart")



kingslayer_chroma <- get_tidy_audio_analysis("7CAbF0By0Fpnbiu6Xn5ZF7") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

kingslayer_chromagram <- kingslayer_chroma %>%
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c(guide = "none", option = "magma") +
  theme(text = element_text(family = "mono")) +
  labs(title = "Kingslayer")



liquor_chroma <- get_tidy_audio_analysis("4djz9dpEMMCYwkADOvrCZL") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

liquor_chromagram <- liquor_chroma %>%
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c(guide = "none", option = "magma") +
  theme(text = element_text(family = "mono")) +
  labs(title = "Liquor & Love Lost")



alotlikevegas_chroma <- get_tidy_audio_analysis("6qa1eyvDHXyaiA6a68kKvr") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

alotlikevegas_chromagram <- alotlikevegas_chroma %>%
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c(guide = "none", option = "magma") +
  theme(text = element_text(family = "mono")) +
  labs(title = "A Lot Like Vegas")


grid.arrange(cyfmh_chromagram, kingslayer_chromagram, liquor_chromagram, alotlikevegas_chromagram,
             nrow = 2, ncol = 2)

```

***

In these chromagrams we can see two very popular songs in the top row (*Can You Feel My Heart* and *Kingslayer (feat. BABYMETAL)*) and two quite unpopular songs in the bottom row (*Liquor & Love Lost* and *A Lot Like Vegas*). As discussed in the introduction, the popular songs are from BMTH's newer music and the unpopular ones from their older music. Although *Can You Feel My Heart* is from *Sempiternal* and is still categorized as "old" music (looking at the popularity plot, it's clearly visible where the popular songs are as outliers).

The main difference we can see between the popular and unpopular songs, is that the popular ones have more distinct areas where a certain pitch is absent, as can be seen by the **black areas**. The high magnitude areas are also a lot clearer and more distinct than in the unpopular songs. *CYFMH* has a clear focus on E and C and *Kinglsayer* is focused on C, C#/Db and B. The unpopular songs basically have **more of everything**, you would be able to make out some areas of focus, but the chromagrams have **a lot less contrast** in them.


### **Chromagrams** for the **happiest and saddest** songs in Bring Me The Horizon's repertoire {data-commentary-width=450}

```{r}
library(spotifyr)
library(compmus)
library(tidyverse)

memorial <- get_tidy_audio_analysis("2VseRAuxHRFtlvr5zP1fKE?si=6d86a7afadaa4b93") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

memorial_chromagram <- memorial %>%
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c(option = "magma") +
  theme(text = element_text(family = "mono")) +
  labs(title = "Memorial")

onebyone <- get_tidy_audio_analysis("6sIbv1oWOuma2qV907MUbk") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

onebyone_chromagram <- onebyone %>%
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c(option = "magma") +
  theme(text = element_text(family = "mono")) +
  labs(title = "1x1 (feat. Nova Twins)")


grid.arrange(memorial_chromagram, onebyone_chromagram, nrow = 2)


```


***

*After plotting the energy and valence of Bring Me The Horizon's songs over the years, it gave me some insight into which songs were on the outer ends of the 'emotional spectrum'. Because of this I decided to take a closer look at the happiest and the saddest songs in their repertoire.*

*Memorial* is, according to its measurements of valence and energy, the **saddest** song in Bring Me The Horizon's entire repertoire. As you can see, the song is **quite repetitive** and has a few layers that really stand out. *Memorial* is an entirely instrumental song with a continuous underlying sound and is used in the album as a transition into the next track. There are clearly audible, and in the chromagram visible, **high and loud 'screeching' noises** in the song and a few notes that are played softly and repeatedly throughout the song. The texture of the song is very simple and also very clearly repesented in this chromagram. Interestingly, despite the fact that we saw that popular songs have a more distinct pattern, this song is not very popular. A good reason for this could be that is instrumental and belongs to the "old" music.

*1x1 (feat. Nova Twins)* is, according to it's measurements of valence and energy, the **happiest** song in Bring Me The Horizon's entire repertoire. As you can see, this song is **all over the place**. The line of C#/Db stands out a little bit, with a higher magnitude overall. The song consists of heavy drums and guitar combined with electronic music and keyboard sounds, all accompanied by the singing voices of either Bring Me The Horizon's frontman Oliver Sykes or the featuring artist the Nova Twins. The only big visible thing that is happening here is at **around 160 seconds**, where the heavy instruments that support the rest of the song go quiet and we hear only a keyboard and a singing voice, which gives a bright block in the G#/Ab line.



### **Chromagrams** for BMTH's singles {data-commentary-width=450}
```{r}
prayforplagues_chroma <- get_tidy_audio_analysis("0zYxfgyqypkG7rRwFqyisT") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

prayforplagues_chromagram <- prayforplagues_chroma %>%
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c(guide = "none", option = "magma") +
  theme(text = element_text(family = "mono")) +
  labs(title = "Pray For Plagues")



chelseasmile_chroma <- get_tidy_audio_analysis("2C5jGbR23YLonV7Lton6fV") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

chelseasmile_chromagram <- chelseasmile_chroma %>%
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c(guide = "none", option = "magma") +
  theme(text = element_text(family = "mono")) +
  labs(title = "Chelsea Smile")



shadowmoses_chroma <- get_tidy_audio_analysis("68osIGtVjM7QWVe6pazLHj") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

shadowmoses_chromagram <- shadowmoses_chroma %>%
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c(guide = "none", option = "magma") +
  theme(text = element_text(family = "mono")) +
  labs(title = "Shadow Moses")



drown_chroma <- get_tidy_audio_analysis("6o39Ln9118FKTMbM4BvcEy") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

drown_chromagram <- drown_chroma %>%
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c(guide = "none", option = "magma") +
  theme(text = element_text(family = "mono")) +
  labs(title = "Drown")


mantra_chroma <- get_tidy_audio_analysis("060RNnzoMay3wKJek1faPc") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

mantra_chromagram <- mantra_chroma %>%
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c(guide = "none", option = "magma") +
  theme(text = element_text(family = "mono")) +
  labs(title = "MANTRA")



ludens_chroma <- get_tidy_audio_analysis("4xWirulal0kGikFE3WSU75") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

ludens_chromagram <- ludens_chroma %>%
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c(guide = "none", option = "magma") +
  theme(text = element_text(family = "mono")) +
  labs(title = "Ludens")

grid.arrange(prayforplagues_chromagram, chelseasmile_chromagram, shadowmoses_chromagram,
             drown_chromagram, mantra_chromagram, ludens_chromagram,
             nrow = 2, ncol = 3)
```

***

These are chromagrams for some singles of Bring Me The Horizon, the top three being from the "old" music category and the bottom three from the "new" music category. Building on what we saw in the previous chromagrams, let's first look at the **overall contrast**. It is clearly visible that the newer the music, the more contrast there is, the lighter areas are brighter and the darker areas are blacker. For *Ludens*, however, the chromagram is a bit brighter all over, so the contrast becomes less strong and it is more similar to *Shadow Moses*. This isn't weird, as fans say this song reminds them a bit of BMTH's old music.


**Timbre** {.storyboard data-icon="fa-music" data-navmenu="Analysis"}
=========================================================

### **Timbre** changes in categories {data-commentary-width=450}
```{r}
old_timbre <-
  get_playlist_audio_features( "",
    "6oeRMX8XZ8IS7MCDb6Z1BG"
  ) %>%
  slice(1:30) %>%
  add_audio_analysis()
new_timbre <-
  get_playlist_audio_features(
    "",
    "4k98rVhcCw54dhLaUMiyLK"
  ) %>%
  slice(1:30) %>%
  add_audio_analysis()
experimental_timbre <-
  get_playlist_audio_features(
    "",
    "1EIpRI9TozVUiehlxAmmHq"
  ) %>%
  slice(1:30) %>%
  add_audio_analysis()

musics <-
  old_timbre %>%
  mutate(genre = "Old music") %>%
  bind_rows(new_timbre %>% mutate(genre = "New music"),
            experimental_timbre %>% mutate(genre = "Experimental music"))

musics %>%
  mutate(
    timbre =
      map(
        segments,
        compmus_summarise,
        timbre,
        method = "mean"
      )
  ) %>%
  select(genre, timbre) %>%
  compmus_gather_timbre() %>%
  ggplot(aes(x = basis, y = value, fill = genre, color = genre)) +
  geom_violin(alpha = 0.8) +
  theme_linedraw() +
  scale_fill_brewer(palette = "Dark2") +
  scale_color_brewer(palette = "Dark2") +
  labs(x = "Spotify Timbre Coefficients", y = "", fill = "Category",
       title = "Timbre differences between the categories") +
  theme(text = element_text(family = "mono")) +
  guides(color = "none")

```

***

This plot shows how the timbre components have changed throughout the different categories I divided their music into. Since the components are ordered by importance, I won't go into all of them. For the **first timbre component**, representing the loudness, we can see that "old music" has a significantly longer tail than the other two categories and thus differs quite a bit in loudness. **The second timbre component** emphasizes the brightness, the ranges in this component are overall very high, but definitely the highest in "old music". Although probably only the "experimental music" has a significantly lower average brightness. **The third component **is correlated to the flatness of the sound. You can see that the "experimental music" sounds a lot flatter than both the old and new music, which don't have a big difference between them. **The fourth component** relates to sounds with a stronger attack, which clearly gets stronger going from "old" to "new" to "experimental".The same thing goes for **the fifth component**. Over all of the other features, it seems that the "old music" has **longer tails** (a wider reach) than both of the other categories, other than that there are no gigantic differences or clear patterns there.

### **Cepstrograms** for the most "average" songs in "old" and "new" music {data-commentary-width=450}

```{r}
  library(spotifyr)
library(ggplot2)
library(tidyverse)
library(compmus)
library(plotly)
library(Rmisc)

swoeo <-
  get_tidy_audio_analysis("1JGhCrOUIPdYG2n6K26SXE") %>% # Change URI.
  compmus_align(sections, segments) %>%                     # Change `bars`
  select(sections) %>%                                      #   in all three
  unnest(sections) %>%                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
          compmus_summarise, timbre,
          method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )

swoeoplot <- swoeo %>%
  compmus_gather_timbre() %>%
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = basis,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  scale_fill_viridis_c(option = "magma") +                              
  theme_classic() +
  labs(title = "Sleep With One Eye Open") +
  theme(text = element_text(family = "mono"))

ouch <-
  get_tidy_audio_analysis("1PWFyfV7yYhlxHZX2g25wS") %>% # Change URI.
  compmus_align(sections, segments) %>%                     # Change `bars`
  select(sections) %>%                                      #   in all three
  unnest(sections) %>%                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
          compmus_summarise, timbre,
          method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )

ouchplot <- ouch %>%
  compmus_gather_timbre() %>%
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = basis,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  scale_fill_viridis_c(option = "magma") +                              
  theme_classic() +
  labs(title = "Ouch") +
  theme(text = element_text(family = "mono"))

library(gridExtra)
grid.arrange(swoeoplot, ouchplot, nrow = 2)

```

***

These are cepstrograms for the songs that lay the closest to the average energy, valence and danceability in BMTH's old music (*Sleep With One Eye Open*) and new music (*Ouch*). Cepstrograms show how the distribution of timbre in the music. As you can see the cepstrograms both have more intensity in the bottom, but *Sleep With One Eye Open* is "squished down" even more than *Ouch*. Both songs have a **focus on the second component (brightness)** and generally go up to c06. You can see that in **the first component (loudness)** *Sleep With One Eye Open* seems to be more uniform with a gradual increase at the beginning, but *Ouch* seems to have more contrasting blocks. *Ouch* seems to have a flatter sound than *Sleep With One Eye Open*, as can be seen from looking at the **third component**.

### **Cepstrograms** for BMTH's singles: *were the "average" songs representative?* {data-commentary-width=450}
```{r,  fig.width = 16, fig.height = 14}
prayforplagues_cep <-
  get_tidy_audio_analysis("0zYxfgyqypkG7rRwFqyisT") %>% # Change URI.
  compmus_align(sections, segments) %>%                     # Change `bars`
  select(sections) %>%                                      #   in all three
  unnest(sections) %>%                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
          compmus_summarise, timbre,
          method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )

prayforplagues_cep_plot <- prayforplagues_cep %>%
  compmus_gather_timbre() %>%
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = basis,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  scale_fill_viridis_c(option = "magma", guide = "none") +                              
  theme_classic() +
  labs(title = "Pray For Plagues") +
  theme(text = element_text(family = "mono"),
        title = element_text(size = 17))

 chelseasmile_cep <-
  get_tidy_audio_analysis("2C5jGbR23YLonV7Lton6fV") %>% # Change URI.
  compmus_align(sections, segments) %>%                     # Change `bars`
  select(sections) %>%                                      #   in all three
  unnest(sections) %>%                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
          compmus_summarise, timbre,
          method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )

chelseasmile_cep_plot <- chelseasmile_cep %>%
  compmus_gather_timbre() %>%
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = basis,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  scale_fill_viridis_c(option = "magma", guide = "none") +                              
  theme_classic() +
  labs(title = "Chelsea Smile") +
  theme(text = element_text(family = "mono"),
        title = element_text(size = 17))



shadowmoses_cep <-
  get_tidy_audio_analysis("68osIGtVjM7QWVe6pazLHj") %>% # Change URI.
  compmus_align(sections, segments) %>%                     # Change `bars`
  select(sections) %>%                                      #   in all three
  unnest(sections) %>%                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
          compmus_summarise, timbre,
          method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )

shadowmoses_cep_plot <- shadowmoses_cep %>%
  compmus_gather_timbre() %>%
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = basis,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  scale_fill_viridis_c(option = "magma", guide = "none") +                              
  theme_classic() +
  labs(title = "Shadow Moses") +
  theme(text = element_text(family = "mono"),
        title = element_text(size = 17))

 drown_cep <-
  get_tidy_audio_analysis("6o39Ln9118FKTMbM4BvcEy") %>% # Change URI.
  compmus_align(sections, segments) %>%                     # Change `bars`
  select(sections) %>%                                      #   in all three
  unnest(sections) %>%                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
          compmus_summarise, timbre,
          method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )

drown_cep_plot <- drown_cep %>%
  compmus_gather_timbre() %>%
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = basis,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  scale_fill_viridis_c(option = "magma", guide = "none") +                              
  theme_classic() +
  labs(title = "Drown") +
  theme(text = element_text(family = "mono"),
        title = element_text(size = 17))



mantra_cep <-
  get_tidy_audio_analysis("060RNnzoMay3wKJek1faPc") %>% # Change URI.
  compmus_align(sections, segments) %>%                     # Change `bars`
  select(sections) %>%                                      #   in all three
  unnest(sections) %>%                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
          compmus_summarise, timbre,
          method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )

mantra_cep_plot <- mantra_cep %>%
  compmus_gather_timbre() %>%
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = basis,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  scale_fill_viridis_c(option = "magma", guide = "none") +                              
  theme_classic() +
  labs(title = "MANTRA") +
  theme(text = element_text(family = "mono"),
        title = element_text(size = 17))

ludens_cep <-
  get_tidy_audio_analysis("4xWirulal0kGikFE3WSU75") %>% # Change URI.
  compmus_align(sections, segments) %>%                     # Change `bars`
  select(sections) %>%                                      #   in all three
  unnest(sections) %>%                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
          compmus_summarise, timbre,
          method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )

ludens_cep_plot <- ludens_cep %>%
  compmus_gather_timbre() %>%
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = basis,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude", title = "Ludens") +
  scale_fill_viridis_c(option = "magma", guide = "none") +                              
  theme_classic() +
  theme(text = element_text(family = "mono"),
        title = element_text(size = 17))


grid.arrange(prayforplagues_cep_plot, chelseasmile_cep_plot, shadowmoses_cep_plot,
             drown_cep_plot, mantra_cep_plot, ludens_cep_plot, nrow = 3, ncol = 3)
```

***

These are cepstrograms for some of BMTH's singles, with the top row belonging to the "old music" category and the bottom row to the "new music". When comparing all these songs to the "most average songs" from both categories as seen in the previous tab, we can see that those were pretty representative for the rest of the music from those categories. The "old music" is more "squished down" into the lower timbre components and the "new music" is stronger in the higher timbre components. Even though we saw that the "average" song for "old music" was **brighter (timbre component C03)**, that does not necessarily apply to the rest of the "old music". As we can see in both categories, it varies from song to song. **Loudness (timbre component C01)** does seem to be stronger in the "new music" than in the "old music", even though we didn't see that clear difference between the "average songs". 

**Self Similarity Matrices** {.storyboard data-icon="fa-music" data-navmenu="Analysis"}
=========================================================


### **Timbre- and pitch-based self-similarity matrices** for popular and not so popular songs {data-commentary-width=400}
```{r, fig.width = 16, fig.height = 8}
cyfmh <-
  get_tidy_audio_analysis("0WSa1sucoNRcEeULlZVQXj") %>% # Change URI.
  compmus_align(bars, segments) %>%                     # Change `bars`
  select(bars) %>%                                      #   in all three
  unnest(bars) %>%                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "mean", norm = "manhattan"              # Change summary & norm.
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
          compmus_summarise, timbre,
          method = "mean", norm = "manhattan"              # Change summary & norm.
      )
  )
cyfmhplot_selfsim <- cyfmh %>%
  compmus_self_similarity(timbre, "cosine") %>% 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none", option = "magma") +
  theme_classic() +
  labs(x = "", y = "") +
  labs(title = "Can You Feel My Heart (T)") +
  theme(text = element_text(family = "mono"),
        title = element_text(size = 12))

kingslayer <-
  get_tidy_audio_analysis("7CAbF0By0Fpnbiu6Xn5ZF7") %>% # Change URI.
  compmus_align(bars, segments) %>%                     # Change `bars`
  select(bars) %>%                                      #   in all three
  unnest(bars) %>%                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "mean", norm = "manhattan"              # Change summary & norm.
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
          compmus_summarise, timbre,
          method = "mean", norm = "manhattan"              # Change summary & norm.
      )
  )
kingslayerplot_selfsim <- kingslayer %>%
  compmus_self_similarity(timbre, "cosine") %>% 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none", option = "magma") +
  theme_classic() +
  labs(x = "", y = "") +
  labs(title = "Kingslayer (T)") +
  theme(text = element_text(family = "mono"),
        title = element_text(size = 12))


liquorandlove <-
  get_tidy_audio_analysis("4djz9dpEMMCYwkADOvrCZL") %>% # Change URI.
  compmus_align(bars, segments) %>%                     # Change `bars`
  select(bars) %>%                                      #   in all three
  unnest(bars) %>%                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "mean", norm = "manhattan"              # Change summary & norm.
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
          compmus_summarise, timbre,
          method = "mean", norm = "manhattan"              # Change summary & norm.
      )
  )
liquorandlove_selfsim <- liquorandlove %>%
  compmus_self_similarity(timbre, "cosine") %>% 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none", option = "magma") +
  theme_classic() +
  labs(x = "", y = "") +
  labs(title = "Liquor & Love Lost (T)") +
  theme(text = element_text(family = "mono"),
        title = element_text(size = 12))

alotlikevegas <-
  get_tidy_audio_analysis("6qa1eyvDHXyaiA6a68kKvr") %>% # Change URI.
  compmus_align(bars, segments) %>%                     # Change `bars`
  select(bars) %>%                                      #   in all three
  unnest(bars) %>%                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "mean", norm = "manhattan"              # Change summary & norm.
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
          compmus_summarise, timbre,
          method = "mean", norm = "manhattan"              # Change summary & norm.
      )
  )
alotlikevegasplot_selfsim <- alotlikevegas %>%
  compmus_self_similarity(timbre, "cosine") %>% 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none", option = "magma") +
  theme_classic() +
  labs(x = "", y = "") +
  labs(title = "A Lot Like Vegas (T)") +
  theme(text = element_text(family = "mono"),
        title = element_text(size = 12))





  cyfmh <-
  get_tidy_audio_analysis("0WSa1sucoNRcEeULlZVQXj") %>% # Change URI.
  compmus_align(bars, segments) %>%                     # Change `bars`
  select(bars) %>%                                      #   in all three
  unnest(bars) %>%                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
          compmus_summarise, timbre,
          method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )
cyfmhplot_selfsimp <- cyfmh %>%
  compmus_self_similarity(pitches, "cosine") %>% 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none", option = "magma") +
  theme_classic() +
  labs(x = "", y = "") +
  labs(title = "Can You Feel My Heart (P)") +
  theme(text = element_text(family = "mono"),
        title = element_text(size = 12))

kingslayer <-
  get_tidy_audio_analysis("7CAbF0By0Fpnbiu6Xn5ZF7") %>% # Change URI.
  compmus_align(bars, segments) %>%                     # Change `bars`
  select(bars) %>%                                      #   in all three
  unnest(bars) %>%                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
          compmus_summarise, timbre,
          method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )
kingslayerplot_selfsimp <- kingslayer %>%
  compmus_self_similarity(pitches, "cosine") %>% 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none", option = "magma") +
  theme_classic() +
  labs(x = "", y = "") +
  labs(title = "Kingslayer (P)") +
  theme(text = element_text(family = "mono"),
        title = element_text(size = 12))


liquorandlove <-
  get_tidy_audio_analysis("4djz9dpEMMCYwkADOvrCZL") %>% # Change URI.
  compmus_align(bars, segments) %>%                     # Change `bars`
  select(bars) %>%                                      #   in all three
  unnest(bars) %>%                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
          compmus_summarise, timbre,
          method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )
liquorandlove_selfsimp <- liquorandlove %>%
  compmus_self_similarity(pitches, "cosine") %>% 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none", option = "magma") +
  theme_classic() +
  labs(x = "", y = "") +
  labs(title = "Liquor & Love Lost (P)") +
  theme(text = element_text(family = "mono"),
        title = element_text(size = 12))

alotlikevegas <-
  get_tidy_audio_analysis("6qa1eyvDHXyaiA6a68kKvr") %>% # Change URI.
  compmus_align(bars, segments) %>%                     # Change `bars`
  select(bars) %>%                                      #   in all three
  unnest(bars) %>%                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
          compmus_summarise, timbre,
          method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )
alotlikevegasplot_selfsimp <- alotlikevegas %>%
  compmus_self_similarity(pitches, "cosine") %>% 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none", option = "magma") +
  theme_classic() +
  labs(x = "", y = "") +
  labs(title = "A Lot Like Vegas (P)") +
  theme(text = element_text(family = "mono"),
        title = element_text(size = 12))


grid.arrange(cyfmhplot_selfsim, cyfmhplot_selfsimp, kingslayerplot_selfsim, kingslayerplot_selfsimp, 
            liquorandlove_selfsim,  liquorandlove_selfsimp, alotlikevegasplot_selfsim, alotlikevegasplot_selfsimp, 
             nrow = 2, ncol = 4)

```

***

These are **timbre- and pitch-based self-similarity matrices** for some of Bring Me The Horizons most popular songs (*Can You Feel My Heart* and *Kingslayer (feat. BABYMETAL)*) and some of their least popular songs (*Liquor & Love Lost* and *A Lot Like Vegas*). **Timbre-wise**, all but *Liquor & Love Lost* seem to have a quite strong pattern. Te **checkerboard pattern** indicates **homogeniety** in the overall structure of the song and shows the pattern of the different sections like verse and chorus. The checkerboard patterns on the popular songs seem to be divided into smaller sections than the pattern on *A Lot Like Vegas*. The greater variety in the popular songs could be a reason for their popularity. The **bright criss-crossing lines** indicate moments in the music that are different from everything else, *Liquor & Love Lost* does not seem to have a lot of those moments, which could be a reason the song is less well-liked. On the other hand, *A Lot Like Vegas* does seem to have quite a bit of those moments, so it is probably a combination with other factors. **Pitch-wise** we can see some similarities with the timbre SSMs. The **checkerboard pattern** still seems to be divided into smaller sections for the popular music against the unpopular music. The one moment that is different from the rest in the timbre-based SSM for *Liquor & Love Lost* doesn't show up in its pitch-based SSM at all.



**Chords, Keys & Modes** {.storyboard data-icon="fa-music" data-navmenu="Analysis"}
=========================================================


### **Chordograms** for BMTH's singles {data-commentary-width=400}


```{r, fig.width = 12, fig.height = 10}
  circshift <- function(v, n) {
    if (n == 0) v else c(tail(v, n), head(v, -n))
  }

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)


chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

ludens <-
  get_tidy_audio_analysis("4xWirulal0kGikFE3WSU75") %>%
  compmus_align(sections, segments) %>%
  select(sections) %>%
  unnest(sections) %>%
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "mean", norm = "manhattan"
      )
  ) 

ludensplot_chord <- ludens %>% 
  compmus_match_pitch_template(
    chord_templates,         # Change to chord_templates if descired
    method = "euclidean",  # Try different distance metrics
    norm = "chebyshev"     # Try different norms
  ) %>%
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none", option = "magma") +
  theme_minimal() +
  labs(x = "Time (s)", y = "", title = "Ludens") +
  theme(text = element_text(family = "mono")) +
  theme(axis.text.y = element_text(size = 11),
        axis.text.x = element_text(size = 11),
        plot.title = element_text(size = 18))

mantra <-
  get_tidy_audio_analysis("060RNnzoMay3wKJek1faPc") %>%
  compmus_align(sections, segments) %>%
  select(sections) %>%
  unnest(sections) %>%
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "mean", norm = "manhattan"
      )
  ) 

mantraplot_chord <- mantra %>% 
  compmus_match_pitch_template(
    chord_templates,         # Change to chord_templates if descired
    method = "euclidean",  # Try different distance metrics
    norm = "chebyshev"     # Try different norms
  ) %>%
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none", option = "magma") +
  theme_minimal() +
  labs(x = "Time (s)", y = "", title = "MANTRA") +
  theme(text = element_text(family = "mono")) +
  theme(axis.text.y = element_text(size = 11),
        axis.text.x = element_text(size = 11),
        plot.title = element_text(size = 18))


drown <-
  get_tidy_audio_analysis("6o39Ln9118FKTMbM4BvcEy") %>%
  compmus_align(sections, segments) %>%
  select(sections) %>%
  unnest(sections) %>%
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "mean", norm = "manhattan"
      )
  ) 

drownplot_chord <- drown %>% 
  compmus_match_pitch_template(
    chord_templates,         # Change to chord_templates if descired
    method = "euclidean",  # Try different distance metrics
    norm = "chebyshev"     # Try different norms
  ) %>%
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none", option = "magma") +
  theme_minimal() +
  labs(x = "Time (s)", y = "", title = "Drown") +
  theme(text = element_text(family = "mono")) +
  theme(axis.text.y = element_text(size = 11),
        axis.text.x = element_text(size = 11),
        plot.title = element_text(size = 18))

shadowmoses <-
  get_tidy_audio_analysis("68osIGtVjM7QWVe6pazLHj") %>%
  compmus_align(sections, segments) %>%
  select(sections) %>%
  unnest(sections) %>%
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "mean", norm = "manhattan"
      )
  ) 

shadowmosesplot_chord <- shadowmoses %>% 
  compmus_match_pitch_template(
    chord_templates,         # Change to chord_templates if descired
    method = "euclidean",  # Try different distance metrics
    norm = "chebyshev"     # Try different norms
  ) %>%
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none", option = "magma") +
  theme_minimal() +
  labs(x = "Time (s)", y = "", title = "Shadow Moses") +
  theme(text = element_text(family = "mono")) +
  theme(axis.text.y = element_text(size = 11),
        axis.text.x = element_text(size = 11),
        plot.title = element_text(size = 18))

chelseasmile <-
  get_tidy_audio_analysis("2C5jGbR23YLonV7Lton6fV") %>%
  compmus_align(sections, segments) %>%
  select(sections) %>%
  unnest(sections) %>%
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "mean", norm = "manhattan"
      )
  ) 

chelseasmileplot_chord <- chelseasmile %>% 
  compmus_match_pitch_template(
    chord_templates,         # Change to chord_templates if descired
    method = "euclidean",  # Try different distance metrics
    norm = "chebyshev"     # Try different norms
  ) %>%
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none", option = "magma") +
  theme_minimal() +
  labs(x = "Time (s)", y = "", title = "Chelsea Smile") +
  theme(text = element_text(family = "mono")) +
  theme(axis.text.y = element_text(size = 11),
        axis.text.x = element_text(size = 11),
        plot.title = element_text(size = 18))

prayforplagues <-
  get_tidy_audio_analysis("0zYxfgyqypkG7rRwFqyisT") %>%
  compmus_align(sections, segments) %>%
  select(sections) %>%
  unnest(sections) %>%
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "mean", norm = "manhattan"
      )
  ) 

prayforplaguesplot_chord <- prayforplagues %>% 
  compmus_match_pitch_template(
    chord_templates,         # Change to chord_templates if descired
    method = "euclidean",  # Try different distance metrics
    norm = "chebyshev"     # Try different norms
  ) %>%
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none", option = "magma") +
  theme_minimal() +
  labs(x = "Time (s)", y = "", title = "Pray For Plagues") +
  theme(text = element_text(family = "mono")) +
  theme(axis.text.y = element_text(size = 11),
        axis.text.x = element_text(size = 11),
        plot.title = element_text(size = 18))


grid.arrange(prayforplaguesplot_chord, chelseasmileplot_chord, 
             shadowmosesplot_chord,
             drownplot_chord, mantraplot_chord, ludensplot_chord, 
             nrow = 2, ncol = 3)





```

***

These are **chordograms** for some of the singles of all of Bring Me The Horizons albums in the old and new music categories (the experimental category doesn't have any singles), arranged from oldest to newest (left to right, top to bottom). As you can see, there is a lot going on in all these songs. When listening to the music you can easily follow along in the chordograms. Loud percussion and distorted guitar sounds can make for **bright yellow lines**, like the one around 70 seconds in *Shadow Moses*. Considering this, it is clearly visible that Bring Me The Horizon keep using this a lot in their music over time. It is interesting to see that the screaming in *Pray For Plagues* leads to less intense recognition of chords, but does not necessarily create the bright yellow areas mentioned before. 

When comparing the songs to see what happened to BMTH's music over time, you could say that **their music has become more varied**. The older songs have a simpler pattern than the newer songs, which have a lot of changes in them.



### How **keys** and **modes** change throughout Bring Me The Horizon's music {data-commentary-width=450}

```{r}
oldvsnew_order <- oldvsnew                             
oldvsnew_order$category <- factor(oldvsnew_order$category,     
                         levels = c("Old music", 
                                    "New music", 
                                    "Experimental"))


ggplot(oldvsnew_order, aes(factor(key), fill = factor(mode))) +
  geom_bar(position = "stack") +
  theme_linedraw() +
  scale_fill_manual(labels = c("Minor", "Major"),
                    values = c("#380087", "#ffc96b")) +
  scale_x_discrete(breaks = c("0", "1", "2", "3", "4", "5", 
                              "6", "7", "8", "9", "10", "11"),
                   labels = c("C","C#", "D", "D#",
                              "E", "F", "F#", "G", "G#",
                              "A", "A#", "B"),
                   limits = c("0", "1", "2", "3", "4", "5", 
                              "6", "7", "8", "9", "10", "11")) +
  labs(y = "Count", x = "Key", 
       fill = "Mode", 
       title = "Keys and modes throughout BMTH's music") +
  theme(text = element_text(family = "mono"),
        axis.text.x = element_text(size = 7)) +
  facet_grid(~ category)

```

***

This graph shows the keys and modes for the different categories I have divided Bring Me The Horizon's music into. It is remarkable, that - even though their new music can generally be classified as happier and more positive, as we've seen earlier - we see **more minor modes** in that category than in their old, sadder and angrier music. Their **least favourite key seems to be D#** (in either mode really) and **most of their songs seem to be in C, C# and G** for both their old and new music. Their old music also focuses a bit more on G# major. For their experimental music, however, they **focus on a key that is not very common in the rest of their repertoire**, which is D. Mostly D major, while most of that music is in the minor mode. The only thing that can not be derived from Spotify's information, is whether they use sharps (#) or flats (♭). These are enharmonic equivalents, which means that C# and Db practically sound the same, but it could actually make a difference for the musician.

**Tempo and Loudness** {.storyboard data-icon="fa-music" data-navmenu="Analysis"}
=========================================================

### **Tempo analysis** for Bring Me The Horizon's repertoire {data-commentary-width=450}

```{r}
old <- get_playlist_audio_features("", "6oeRMX8XZ8IS7MCDb6Z1BG")
new <- get_playlist_audio_features("", "4k98rVhcCw54dhLaUMiyLK")
experimental <- get_playlist_audio_features("", "1EIpRI9TozVUiehlxAmmHq")

oldvsnew <-
  bind_rows(
    old %>% mutate(category = "Old music"),
    new %>% mutate(category = "New music"),
    experimental %>% mutate(category = "Experimental")
  )

ggplot(oldvsnew, aes(track.album.name, tempo, color = category)) +
  geom_point(size = 3, alpha = 0.6) +
  theme_linedraw() +
  scale_color_brewer(palette = "Dark2") +
  scale_x_discrete(breaks = c("Count Your Blessings",
                              "Suicide Season",
                              "There is a Hell Believe Me I've Seen It. There is a Heaven Let's Keep it a Secret",
                              "Sempiternal (Expanded Edition)",
                              "That's The Spirit",
                              "amo",
                              "Music to listen to~dance to~blaze to~pray to~feed to~sleep to~talk to~grind to~trip to~breathe to~help to~hurt to~scroll to~roll to~love to~hate to~learn Too~plot to~play to~be to~feel to~breed to~sweat to~dream to~hide to~live to~die to~GO TO",
                              "POST HUMAN: SURVIVAL HORROR"),
                   labels = c("Count Your Blessings",
                              "Suicide Season", 
                              "There is a Hell...",
                              "Sempiternal",
                              "That's The Spirit",
                              "amo",
                              "Music to listen to~",
                              "POST HUMAN"),
                   limits = c("Count Your Blessings",
                              "Suicide Season",
                              "There is a Hell Believe Me I've Seen It. There is a Heaven Let's Keep it a Secret",
                              "Sempiternal (Expanded Edition)",
                              "That's The Spirit",
                              "amo",
                              "Music to listen to~dance to~blaze to~pray to~feed to~sleep to~talk to~grind to~trip to~breathe to~help to~hurt to~scroll to~roll to~love to~hate to~learn Too~plot to~play to~be to~feel to~breed to~sweat to~dream to~hide to~live to~die to~GO TO",
                              "POST HUMAN: SURVIVAL HORROR")
  ) +
  theme(text = element_text(family = "mono")) +
  theme(axis.text.x = element_text(angle = 60, hjust = 1, size = 8)) +
  theme(axis.title.x = element_blank()) +
  labs(y = "Tempo (BPM)", title = "Tempo for BMTH's music per album", color = "Category") +
  stat_summary(
    geom = "point",
    fun = "median",
    col = "darkred",
    size = 7,
    shape = 21,
    fill = "pink",
    alpha = 0.5
  ) +
  stat_summary(aes(group = 1), 
               fun = median, 
               geom = "line", 
               colour = "darkred",
               alpha = 0.3) 


```

***

This plot displays the tempo in beats per minute for Bring Me The Horizon's entire repertoire, the albums are sorted by their release date and each dot represents a song. The bigger red/pink circles represent the **median for the tempo for each album**. It is interesting to see that their old music has the lowest tempo and it starts climbing up when their music starts to drift away from the "metalcore" genre. In their newer music the mean line almost seems to be coherent with the means of popularity for these albums.

### **Loudness** for Bring Me The Horizon's repertoire {data-commentary-width=450}
```{r}
old <- get_playlist_audio_features("", "6oeRMX8XZ8IS7MCDb6Z1BG")
new <- get_playlist_audio_features("", "4k98rVhcCw54dhLaUMiyLK")
experimental <- get_playlist_audio_features("", "1EIpRI9TozVUiehlxAmmHq")

oldvsnew <-
  bind_rows(
    old %>% mutate(category = "Old music"),
    new %>% mutate(category = "New music"),
    experimental %>% mutate(category = "Experimental")
  )

ggplot(oldvsnew, aes(track.album.name, loudness, color = category)) +
  geom_point(size = 3, alpha = 0.6) +
  theme_linedraw() +
  scale_color_brewer(palette = "Dark2") +
  scale_x_discrete(breaks = c("Count Your Blessings",
                              "Suicide Season",
                              "There is a Hell Believe Me I've Seen It. There is a Heaven Let's Keep it a Secret",
                              "Sempiternal (Expanded Edition)",
                              "That's The Spirit",
                              "amo",
                              "Music to listen to~dance to~blaze to~pray to~feed to~sleep to~talk to~grind to~trip to~breathe to~help to~hurt to~scroll to~roll to~love to~hate to~learn Too~plot to~play to~be to~feel to~breed to~sweat to~dream to~hide to~live to~die to~GO TO",
                              "POST HUMAN: SURVIVAL HORROR"),
                   labels = c("Count Your Blessings",
                              "Suicide Season", 
                              "There is a Hell...",
                              "Sempiternal",
                              "That's The Spirit",
                              "amo",
                              "Music to listen to~",
                              "POST HUMAN"),
                   limits = c("Count Your Blessings",
                              "Suicide Season",
                              "There is a Hell Believe Me I've Seen It. There is a Heaven Let's Keep it a Secret",
                              "Sempiternal (Expanded Edition)",
                              "That's The Spirit",
                              "amo",
                              "Music to listen to~dance to~blaze to~pray to~feed to~sleep to~talk to~grind to~trip to~breathe to~help to~hurt to~scroll to~roll to~love to~hate to~learn Too~plot to~play to~be to~feel to~breed to~sweat to~dream to~hide to~live to~die to~GO TO",
                              "POST HUMAN: SURVIVAL HORROR")
  ) +
  theme(text = element_text(family = "mono")) +
  theme(axis.text.x = element_text(angle = 60, hjust = 1, size = 8)) +
  theme(axis.title.x = element_blank()) +
  labs(y = "Loudness (dB)", title = "Loudness per track for BMTH's music per album", color = "Category") +
  stat_summary(
    geom = "point",
    fun = "median",
    col = "darkred",
    size = 7,
    shape = 21,
    fill = "pink",
    alpha = 0.5
  ) +
  stat_summary(aes(group = 1), 
               fun = median, 
               geom = "line", 
               colour = "darkred",
               alpha = 0.3) +
  ylim(-14, -1)

```

***

This plot shows the loudness per track for all of BMTH's albums, from oldest-newest from left to right, coloured by category (I have scaled the Y-axis to remove one song from *There is a Hell...*, as it had a loudness of -22 and made the rest of the plot hard to read). The larger red/pink circles show the **median** of the loudness per album.  As we have seen in the **timbre analysis**, the "new music" is slightly stronger in the timbre component that indicates loudness and that is visible in this plot. This plot also shows, as a lot of other parts of the analysis have, that the "experimental music" has very different scores from the rest of BMTH's music.

**Classification** {.storyboard data-icon="fa-music" data-navmenu="Analysis"}
=========================================================

### **Classification** {data-commentary-width=450}

```{r}
old <- get_playlist_audio_features("", "6oeRMX8XZ8IS7MCDb6Z1BG")
new <- get_playlist_audio_features("", "4k98rVhcCw54dhLaUMiyLK")
experimental <- get_playlist_audio_features("", "1EIpRI9TozVUiehlxAmmHq")

oldvsnew_classification <-
  bind_rows(
    old %>% mutate(playlist = "Old") %>% slice_head(n = 30),
    new %>% mutate(playlist = "New") %>% slice_head(n = 30),
    experimental %>% mutate(playlist = "Experimental") %>% slice_head(n = 30)
  ) 


oldvsnew_features <-
  oldvsnew_classification %>%  # For your portfolio, change this to the name of your corpus.
  add_audio_analysis() %>% 
  mutate(
    playlist = factor(playlist),
    segments = map2(segments, key, compmus_c_transpose),
    pitches =
      map(
        segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      ),
    timbre =
      map(
        segments,
        compmus_summarise, timbre,
        method = "mean",
      )
  ) %>%
  mutate(pitches = map(pitches, compmus_normalise, "clr")) %>%
  mutate_at(vars(pitches, timbre), map, bind_rows) %>%
  unnest(cols = c(pitches, timbre))

```

```{r}
oldvsnew_recipe <-
  recipe(
    playlist ~
      energy +
     valence +
      duration +
      c01 + c02 + c03 + c04 + c05 + c06 +
      c07 + c08 + c09 + c10 + c11 + c12,
    data = oldvsnew_features,          # Use the same name as the previous block.
  ) %>%
  step_center(all_predictors()) %>%
  step_scale(all_predictors())      # Converts to z-scores.
  # step_range(all_predictors())    # Sets range to [0, 1].

```

```{r}
oldvsnew_cv <- oldvsnew_features %>% vfold_cv(5)


knn_model <-
  nearest_neighbor(neighbors = 1) %>%
  set_mode("classification") %>% 
  set_engine("kknn")
oldvsnew_knn <- 
  workflow() %>% 
  add_recipe(oldvsnew_recipe) %>% 
  add_model(knn_model) %>% 
  fit_resamples(
    oldvsnew_cv, 
    control = control_resamples(save_pred = TRUE)
  )


 oldvsnew_knn %>% get_conf_mat() %>% autoplot(type = "mosaic")
 
```



*** 
Here I have trained a classifier to distinguish between the three different categories I divided Bring Me The Horizon's music into. After trying different combinations, I figured out that **energy, valence, duration and all of the timbre components** are the most useful features for computational recognition of this corpus. The **keys** generally confused the classifier the most and **duration** seemed to influence the experimental category the most (significantly fewer songs were classified correctly). As you can see in the mosaic plot, **most of the music is classified in the right category**. It is important to mention that for both old and new 30 songs were used, but there are only eight experimental songs. Considering this, it's quite remarkable that five out of those eight are classified correctly here.

The precision rates are very high for all of the categories, 83% for experimental music, 82% for new music and even 96% for old music. The categories I divided the music into are thus very distinguishable from each other, especially when filtering out the right elements (even without doing this the scores are still relatively high).

***
**A plot showing the numbers**
```{r, fig.width=3, fig.height=3}
oldvsnew_knn %>% get_conf_mat() %>% autoplot(type = "heatmap")
```



### Comparing mportant features for the classifier: **Engergy, valence** and **duration**
```{r, fig.width=10, fig.height=5}
old <- get_playlist_audio_features("", "6oeRMX8XZ8IS7MCDb6Z1BG")
new <- get_playlist_audio_features("", "4k98rVhcCw54dhLaUMiyLK")
experimental <- get_playlist_audio_features("", "1EIpRI9TozVUiehlxAmmHq")

oldvsnew <-
  bind_rows(
    old %>% mutate(category = "Old music"),
    new %>% mutate(category = "New music"),
    experimental %>% mutate(category = "Experimental")
  )

energy_plot_class_category <- ggplot(oldvsnew, aes(category, energy, color = category)) +
  geom_point(size = 3, alpha = 0.6) +
  theme_linedraw() +
  scale_color_brewer(palette = "Dark2",  name = "", labels = c("Experimental", "New", "Old")) +
  scale_x_discrete(breaks = c("Old music", "New music", "Experimental"),
                   labels = c("Old music", "New music", "Experimental"),
                   limits = c("Old music", "New music", "Experimental")
  ) +
  theme(text = element_text(family = "mono")) +
  theme(axis.text.x = element_text(angle = 60, hjust = 1, size = 8)) +
  theme(axis.title.x = element_blank()) +
  labs(y = "Energy", color = "Category", title = "Energy") +
  stat_summary(
    geom = "point",
    fun = "median",
    col = "darkred",
    size = 7,
    shape = 21,
    fill = "pink",
    alpha = 0.5
  ) +
  stat_summary(aes(group = 1), 
               fun = median, 
               geom = "line", 
               colour = "darkred",
               alpha = 0.3) +
  theme(legend.position = "top")

valence_plot_class_category <- ggplot(oldvsnew, aes(category, valence, color = category)) +
  geom_point(size = 3, alpha = 0.6) +
  theme_linedraw() +
  scale_color_brewer(palette = "Dark2",  name = "", labels = c("Experimental", "New", "Old")) +
  scale_x_discrete(breaks = c("Old music", "New music", "Experimental"),
                   labels = c("Old music", "New music", "Experimental"),
                   limits = c("Old music", "New music", "Experimental")
  ) +
  theme(text = element_text(family = "mono")) +
  theme(axis.text.x = element_text(angle = 60, hjust = 1, size = 8)) +
  theme(axis.title.x = element_blank()) +
  labs(y = "Valence", color = "Category", title = "Valence") +
  stat_summary(
    geom = "point",
    fun = "median",
    col = "darkred",
    size = 7,
    shape = 21,
    fill = "pink",
    alpha = 0.5
  ) +
  stat_summary(aes(group = 1), 
               fun = median, 
               geom = "line", 
               colour = "darkred",
               alpha = 0.3) +
  theme(legend.position = "top")


duration_plot_class_category <- ggplot(oldvsnew, aes(category, track.duration_ms, color = category)) +
  geom_point(size = 3, alpha = 0.6) +
  theme_linedraw() +
  scale_color_brewer(palette = "Dark2", name = "", labels = c("Experimental", "New", "Old")) +
  scale_x_discrete(breaks = c("Old music", "New music", "Experimental"),
                   labels = c("Old music", "New music", "Experimental"),
                   limits = c("Old music", "New music", "Experimental")
  ) +
  theme(text = element_text(family = "mono")) +
  theme(axis.text.x = element_text(angle = 60, hjust = 1, size = 8)) +
  theme(axis.title.x = element_blank()) +
  labs(y = "Duration (ms)", color = "Category", title = "Duration") +
  stat_summary(
    geom = "point",
    fun = "median",
    col = "darkred",
    size = 7,
    shape = 21,
    fill = "pink",
    alpha = 0.5
  ) +
  stat_summary(aes(group = 1), 
               fun = median, 
               geom = "line", 
               colour = "darkred",
               alpha = 0.3) +
  theme(legend.position = "top") +
  ylim(0, 750000) 

grid.arrange(valence_plot_class_category, energy_plot_class_category, duration_plot_class_category,
             nrow = 1, ncol = 3)

```

***
These plots show three of the most **important elements for the classifier** per category it classifies. The bigger red/pink circles show the median of each value per category. As you can see, **Valence** is the most important element for the "new music", since it is focused much higher in that category. **Energy** doesn't look like it should have too much influence in the "old" and "new" categories, but "experimental" has very different scores. This happens for the **duration** as well.

Conclusion {data-icon="fa-comment-dots" .rows}
=============================================================================

Column 1
------------------------------------------------------

### What has changed?
Bring Me The Horizon's music has strongly changed over the years, you could easily say that even without making an analysis like this one. First, let's look at what has changed in their new music: overall it seems to have more variation. This is not only visible from the very first plot that relates the energy to the valence, but also in the chromagrams (they show more contrast than for their old music), in the cepstrograms (which show that the timbre is formed by and stronger in more components than in their old music) and the self-similarity matrices (which show more varied patterns). Speaking of patterns, those seem to have become clearer and more structured in BMTH's new music. The timbre features also show that their music has become less bright. Their music has also become louder and faster than it used to be. For a lot of people this would mean that it sounds angrier, but on the contrary, their music has actually become more positive in terms of valence. Their new music still has more songs in minor mode than their old music though, but a minor mode does not always mean the song actually sounds or is sad.

### What has remained the same?
One of the aspects that has remained the same is the keys BMTH use in their music, they still don't like D# and prefer to use C, C# and G. Even though I said that their new songs have a more apparent structure, in most of their songs you can still see a lot going on, just like in their old music. Also, the higher valence levels indicate more positive music, but the scores are still mostly below 0.5 out of 1. Their music is more positive, but still not *actually* positive.

Column 2
---------------------------------------------

### On popularity
It is very clear that Bring Me The Horizon's new music scores a lot higher on popularity, with *Sempiternal* being a kind of "transitional" album. It still fits into the "old", but has a lot of features from the "new". Does the higher popularity of their newer work mean people prefer louder, higher tempo, more positive music that has more structure? Maybe, but maybe it is also because BMTH's old music is just "old", and society requires new stimuli at the speed of light nowadays. Or most people prefer alternative-/pop-/electronic-rock over metalcore, who knows. This would certainly be an area that is interesting for further research, perhaps related to something like *cultural musicology*.

### The experimental music
As we have seen basically everywhere in the analysis, the experimental music that Bring Me The Horizon has made is just *different* from the rest. It doesn't fit into any category of music they have made before (or after, so far) and that really shows. The popularity drops down with the release of *Music to listen to~*, when their albums right before and after that score almost 50% higher on average. I didn't want to focus my research on this experimental aspect, so apart from general features to look at we'll just have to accept it's difference for now.


